{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Machine Translation and LSH\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This analysis covers the folowing topics:\n",
    "\n",
    "- [1. The word embeddings data for English and French words](#1)\n",
    "  - [1.1 Generate embedding and transform matrices](#1-1)\n",
    "- [2. Translations](#2)\n",
    "  - [2.1 Translation as linear transformation of embeddings](#2-1)      \n",
    "  - [2.2 Testing the translation](#2-2)    \n",
    "- [3. LSH and document search](#3)\n",
    "  - [3.1 Getting the document embeddings](#3-1)\n",
    "  - [3.2 Looking up the tweets](#3-2)\n",
    "  - [3.3 Finding the most similar tweets with LSH](#3-3)\n",
    "  - [3.4 Getting the hash number for a vector](#3-4)\n",
    "  - [3.5 Creating a hash table](#3-5)\n",
    "  - [3.6 Creating all hash tables](#3-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdb\n",
    "import pickle\n",
    "import string\n",
    "\n",
    "import time\n",
    "\n",
    "import gensim\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "import numpy as np\n",
    "import scipy\n",
    "import sklearn\n",
    "from gensim.models import KeyedVectors\n",
    "from nltk.corpus import stopwords, twitter_samples\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "\n",
    "from utils import (cosine_similarity, get_dict,\n",
    "                   process_tweet)\n",
    "from os import getcwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "filePath = f\"{getcwd()}/../tmp2/\"\n",
    "nltk.data.path.append(filePath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"1\"></a>\n",
    "\n",
    "# 1. The word embeddings data for English and French words\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The subset of data\n",
    "\n",
    "To do the assignment on the Coursera workspace, we'll use the subset of word embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_embeddings_subset = pickle.load(open(\"en_embeddings.p\", \"rb\"))\n",
    "fr_embeddings_subset = pickle.load(open(\"fr_embeddings.p\", \"rb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load two dictionaries mapping the English to French words\n",
    "* A training dictionary\n",
    "* and a testing dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of the English to French training dictionary is 5000\n",
      "The length of the English to French test dictionary is 5000\n"
     ]
    }
   ],
   "source": [
    "# loading the english to french dictionaries\n",
    "en_fr_train = get_dict('en-fr.train.txt')\n",
    "print('The length of the English to French training dictionary is', len(en_fr_train))\n",
    "en_fr_test = get_dict('en-fr.test.txt')\n",
    "print('The length of the English to French test dictionary is', len(en_fr_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"1-1\"></a>\n",
    "\n",
    "## 1.1 Generate embedding and transform matrices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_matrices(en_fr, french_vecs, english_vecs):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "        en_fr: English to French dictionary\n",
    "        french_vecs: French words to their corresponding word embeddings.\n",
    "        english_vecs: English words to their corresponding word embeddings.\n",
    "    Output: \n",
    "        X: a matrix where the columns are the English embeddings.\n",
    "        Y: a matrix where the columns correspong to the French embeddings.\n",
    "        R: the projection matrix that minimizes the F norm ||X R -Y||^2.\n",
    "    \"\"\"\n",
    "\n",
    "    X_l = list()\n",
    "    Y_l = list()\n",
    "\n",
    "    english_set = set(english_vecs.keys())\n",
    "    french_set = set(french_vecs.keys())\n",
    "    french_words = set(en_fr.values())\n",
    "\n",
    "    for en_word, fr_word in en_fr.items():\n",
    "\n",
    "        if fr_word in french_set and en_word in english_set:\n",
    "            en_vec = english_vecs[en_word]\n",
    "            fr_vec = french_vecs[fr_word]\n",
    "            X_l.append(en_vec)\n",
    "            Y_l.append(fr_vec)\n",
    "\n",
    "\n",
    "    X = np.vstack(X_l)\n",
    "    Y = np.vstack(Y_l)\n",
    "\n",
    "    return X, Y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will use function `get_matrices()` to obtain sets `X_train` and `Y_train`\n",
    "of English and French word embeddings into the corresponding vector space models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, Y_train = get_matrices(\n",
    "    en_fr_train, fr_embeddings_subset, en_embeddings_subset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Translations\n",
    "\n",
    "## 2.1 Translation as linear transformation of embeddings\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Describing translation as the minimization problem\n",
    "\n",
    "Find a matrix `R` that minimizes the following equation. \n",
    "\n",
    "$$\\arg \\min _{\\mathbf{R}}\\| \\mathbf{X R} - \\mathbf{Y}\\|_{F}\\tag{1} $$\n",
    "\n",
    "### Frobenius norm\n",
    "\n",
    "The Frobenius norm of a matrix $A$ (assuming it is of dimension $m,n$) is defined as the square root of the sum of the absolute squares of its elements:\n",
    "\n",
    "$$\\|\\mathbf{A}\\|_{F} \\equiv \\sqrt{\\sum_{i=1}^{m} \\sum_{j=1}^{n}\\left|a_{i j}\\right|^{2}}\\tag{2}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Actual loss function\n",
    "In the real world applications, the Frobenius norm loss:\n",
    "\n",
    "$$\\| \\mathbf{XR} - \\mathbf{Y}\\|_{F}$$\n",
    "\n",
    "is often replaced by it's squared value divided by $m$:\n",
    "\n",
    "$$ \\frac{1}{m} \\|  \\mathbf{X R} - \\mathbf{Y} \\|_{F}^{2}$$\n",
    "\n",
    "where $m$ is the number of examples (rows in $\\mathbf{X}$).\n",
    "\n",
    "* The same R is found when using this loss function versus the original Frobenius norm.\n",
    "* The reason for taking the square is that it's easier to compute the gradient of the squared Frobenius.\n",
    "* The reason for dividing by $m$ is that we're more interested in the average loss per embedding than the  loss for the entire training set.\n",
    "    * The loss for all training set increases with more words (training examples),\n",
    "    so taking the average helps us to track the average loss regardless of the size of the training set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"ex-02\"></a>\n",
    "\n",
    "### Implementing translation mechanism described in this section.\n",
    "\n",
    "#### Step 1: Computing the loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_loss(X, Y, R):\n",
    "    '''\n",
    "    Inputs: \n",
    "        X: a matrix of dimension (m,n) where the columns are the English embeddings.\n",
    "        Y: a matrix of dimension (m,n) where the columns correspong to the French embeddings.\n",
    "        R: a matrix of dimension (n,n) - transformation matrix from English to French vector space embeddings.\n",
    "    Outputs:\n",
    "        L: a matrix of dimension (m,n) - the value of the loss function for given X, Y and R.\n",
    "    '''\n",
    "\n",
    "    m = len(X)\n",
    "    diff = np.dot(X,R) -Y\n",
    "    diff_squared = np.square(diff)\n",
    "    sum_diff_squared = np.sum(diff_squared)\n",
    "    loss = sum_diff_squared/m\n",
    "\n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"ex-03\"></a>\n",
    "\n",
    "### Step 2: Computing the gradient of loss in respect to transform matrix R\n",
    "\n",
    "\n",
    "$$\\frac{d}{dR}ùêø(ùëã,ùëå,ùëÖ)=\\frac{d}{dR}\\Big(\\frac{1}{m}\\| X R -Y\\|_{F}^{2}\\Big) = \\frac{2}{m}X^{T} (X R - Y)$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_gradient(X, Y, R):\n",
    "    '''\n",
    "    Inputs: \n",
    "        X: a matrix of dimension (m,n) where the columns are the English embeddings.\n",
    "        Y: a matrix of dimension (m,n) where the columns correspong to the French embeddings.\n",
    "        R: a matrix of dimension (n,n) - transformation matrix from English to French vector space embeddings.\n",
    "    Outputs:\n",
    "        g: a scalar value - gradient of the loss function L for given X, Y and R.\n",
    "    '''\n",
    "\n",
    "    m = len(X)\n",
    "    gradient = np.dot(X.T,(np.dot(X,R)-Y))*2/m\n",
    "    return gradient\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Finding the optimal R with gradient descent algorithm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training with a fixed number of iterations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def align_embeddings(X, Y, train_steps=100, learning_rate=0.0003):\n",
    "    '''\n",
    "    Inputs:\n",
    "        X: a matrix of dimension (m,n) where the columns are the English embeddings.\n",
    "        Y: a matrix of dimension (m,n) where the columns correspong to the French embeddings.\n",
    "        train_steps: positive int - describes how many steps will gradient descent algorithm do.\n",
    "        learning_rate: positive float - describes how big steps will  gradient descent algorithm do.\n",
    "    Outputs:\n",
    "        R: a matrix of dimension (n,n) - the projection matrix that minimizes the F norm ||X R -Y||^2\n",
    "    '''\n",
    "    np.random.seed(129)\n",
    "\n",
    "    R = np.random.rand(X.shape[1], X.shape[1])\n",
    "\n",
    "    for i in range(train_steps):\n",
    "        if i % 25 == 0:\n",
    "            print(f\"loss at iteration {i} is: {compute_loss(X, Y, R):.4f}\")\n",
    "        gradient = compute_gradient(X,Y,R)\n",
    "        R -= gradient*learning_rate\n",
    "    return R\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss at iteration 0 is: 3.7242\n",
      "loss at iteration 25 is: 3.6283\n",
      "loss at iteration 50 is: 3.5350\n",
      "loss at iteration 75 is: 3.4442\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(129)\n",
    "m = 10\n",
    "n = 5\n",
    "X = np.random.rand(m, n)\n",
    "Y = np.random.rand(m, n) * .1\n",
    "R = align_embeddings(X, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate transformation matrix R\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss at iteration 0 is: 963.0146\n",
      "loss at iteration 25 is: 97.8292\n",
      "loss at iteration 50 is: 26.8329\n",
      "loss at iteration 75 is: 9.7893\n",
      "loss at iteration 100 is: 4.3776\n",
      "loss at iteration 125 is: 2.3281\n",
      "loss at iteration 150 is: 1.4480\n",
      "loss at iteration 175 is: 1.0338\n",
      "loss at iteration 200 is: 0.8251\n",
      "loss at iteration 225 is: 0.7145\n",
      "loss at iteration 250 is: 0.6534\n",
      "loss at iteration 275 is: 0.6185\n",
      "loss at iteration 300 is: 0.5981\n",
      "loss at iteration 325 is: 0.5858\n",
      "loss at iteration 350 is: 0.5782\n",
      "loss at iteration 375 is: 0.5735\n"
     ]
    }
   ],
   "source": [
    "R_train = align_embeddings(X_train, Y_train, train_steps=400, learning_rate=0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"2-2\"></a>\n",
    "\n",
    "## 2.2 Testing the translation\n",
    "\n",
    "### k-Nearest neighbors algorithm\n",
    "\n",
    "[k-Nearest neighbors algorithm](https://en.wikipedia.org/wiki/K-nearest_neighbors_algorithm) \n",
    "* k-NN is a method which takes a vector as input and finds the other vectors in the dataset that are closest to it. \n",
    "* The 'k' is the number of \"nearest neighbors\" to find (e.g. k=2 finds the closest two neighbors).\n",
    "\n",
    "### Searching for the translation embedding\n",
    "Since we're approximating the translation function from English to French embeddings by a linear transformation matrix $\\mathbf{R}$, most of the time we won't get the exact embedding of a French word when we transform embedding $\\mathbf{e}$ of some particular English word into the French embedding space. \n",
    "* By using $1$-NN with $\\mathbf{eR}$ as input, we can search for an embedding $\\mathbf{f}$ (as a row) in the matrix $\\mathbf{Y}$ which is the closest to the transformed vector $\\mathbf{eR}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nearest_neighbor(v, candidates, k=1):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "      - v, the vector you are going find the nearest neighbor for\n",
    "      - candidates: a set of vectors where we will find the neighbors\n",
    "      - k: top k nearest neighbors to find\n",
    "    Output:\n",
    "      - k_idx: the indices of the top k closest vectors in sorted form\n",
    "    \"\"\"\n",
    "    similarity_l = []\n",
    "\n",
    "    for row in candidates:\n",
    "        cos_similarity = cosine_similarity(np.array(row).flatten(), np.array(v).flatten())\n",
    "\n",
    "        similarity_l.append(cos_similarity)\n",
    "        \n",
    "    sorted_ids = np.argsort(similarity_l)\n",
    "\n",
    "    k_idx = sorted_ids[-k:]\n",
    "    return k_idx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[9 9 9]\n",
      " [1 0 5]\n",
      " [2 0 1]]\n"
     ]
    }
   ],
   "source": [
    "v = np.array([1, 0, 1])\n",
    "candidates = np.array([[1, 0, 5], [-2, 5, 3], [2, 0, 1], [6, -9, 5], [9, 9, 9]])\n",
    "print(candidates[nearest_neighbor(v, candidates, 3)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test translation and compute its accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_vocabulary(X, Y, R):\n",
    "    '''\n",
    "    Input:\n",
    "        X: a matrix where the columns are the English embeddings.\n",
    "        Y: a matrix where the columns correspong to the French embeddings.\n",
    "        R: the transform matrix which translates word embeddings from\n",
    "        English to French word vector space.\n",
    "    Output:\n",
    "        accuracy: for the English to French capitals\n",
    "    '''\n",
    "\n",
    "    pred = np.dot(X, R)\n",
    "    num_correct = 0\n",
    "\n",
    "    for i in range(len(pred)):\n",
    "        pred_idx = nearest_neighbor(pred[i],Y, k=1)\n",
    "        if pred_idx == i:\n",
    "            num_correct += 1\n",
    "\n",
    "    accuracy = num_correct/ len(pred)\n",
    "\n",
    "    return accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val, Y_val = get_matrices(en_fr_test, fr_embeddings_subset, en_embeddings_subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy on test set is 0.557\n"
     ]
    }
   ],
   "source": [
    "\n",
    "acc = test_vocabulary(X_val, Y_val, R_train) \n",
    "print(f\"accuracy on test set is {acc:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"3\"></a>\n",
    "\n",
    "# 3. LSH and document search\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the positive and negative tweets\n",
    "all_positive_tweets = twitter_samples.strings('positive_tweets.json')\n",
    "all_negative_tweets = twitter_samples.strings('negative_tweets.json')\n",
    "all_tweets = all_positive_tweets + all_negative_tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"3-1\"></a>\n",
    "\n",
    "### 3.1 Getting the document embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UNQ_C12 (UNIQUE CELL IDENTIFIER, DO NOT EDIT)\n",
    "def get_document_embedding(tweet, en_embeddings): \n",
    "    '''\n",
    "    Input:\n",
    "        - tweet: a string\n",
    "        - en_embeddings: a dictionary of word embeddings\n",
    "    Output:\n",
    "        - doc_embedding: sum of all word embeddings in the tweet\n",
    "    '''\n",
    "    doc_embedding = np.zeros(300)\n",
    "\n",
    "    processed_doc = process_tweet(tweet)\n",
    "    for word in processed_doc:\n",
    "        doc_embedding += en_embeddings.get(word,np.zeros(300))\n",
    "    return doc_embedding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.00268555, -0.15378189, -0.55761719, -0.07216644, -0.32263184])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom_tweet = \"RT @Twitter @chapagain Hello There! Have a great day. :) #good #morning http://chapagain.com.np\"\n",
    "tweet_embedding = get_document_embedding(custom_tweet, en_embeddings_subset)\n",
    "tweet_embedding[-5:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"ex-08\"></a>\n",
    "\n",
    "#### Store all document vectors into a dictionary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_document_vecs(all_docs, en_embeddings):\n",
    "    '''\n",
    "    Input:\n",
    "        - all_docs: list of strings - all tweets in our dataset.\n",
    "        - en_embeddings: dictionary with words as the keys and their embeddings as the values.\n",
    "    Output:\n",
    "        - document_vec_matrix: matrix of tweet embeddings.\n",
    "        - ind2Doc_dict: dictionary with indices of tweets in vecs as keys and their embeddings as the values.\n",
    "    '''\n",
    "\n",
    "    ind2Doc_dict = {}\n",
    "    document_vec_l = []\n",
    "\n",
    "    for i, doc in enumerate(all_docs):\n",
    "\n",
    "\n",
    "        doc_embedding = get_document_embedding(doc, en_embeddings)\n",
    "        ind2Doc_dict[i] = doc_embedding\n",
    "        document_vec_l.append( ind2Doc_dict[i])\n",
    "        \n",
    "    document_vec_matrix = np.vstack(document_vec_l)\n",
    "\n",
    "    return document_vec_matrix, ind2Doc_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "document_vecs, ind2Tweet = get_document_vecs(all_tweets, en_embeddings_subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of dictionary 10000\n",
      "shape of document_vecs (10000, 300)\n"
     ]
    }
   ],
   "source": [
    "print(f\"length of dictionary {len(ind2Tweet)}\")\n",
    "print(f\"shape of document_vecs {document_vecs.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"3-2\"></a>\n",
    "\n",
    "## 3.2 Looking up the tweets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_tweet = 'i am sad'\n",
    "process_tweet(my_tweet)\n",
    "tweet_embedding = get_document_embedding(my_tweet, en_embeddings_subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@zoeeylim sad sad sad kid :( it's ok I help you watch the match HAHAHAHAHA\n"
     ]
    }
   ],
   "source": [
    "idx = np.argmax(cosine_similarity(document_vecs, tweet_embedding))\n",
    "print(all_tweets[idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"3-3\"></a>\n",
    "\n",
    "## 3.3 Finding the most similar tweets with LSH\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of vectors is 10000 and each has 300 dimensions.\n"
     ]
    }
   ],
   "source": [
    "N_VECS = len(all_tweets)       # This many vectors.\n",
    "N_DIMS = len(ind2Tweet[1])     # Vector dimensionality.\n",
    "print(f\"Number of vectors is {N_VECS} and each has {N_DIMS} dimensions.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Choosing the number of planes\n",
    "\n",
    "* Each plane divides the space to $2$ parts.\n",
    "* So $n$ planes divide the space into $2^{n}$ hash buckets.\n",
    "* We want to organize 10,000 document vectors into buckets so that every bucket has about $~16$ vectors.\n",
    "* For that we need $\\frac{10000}{16}=625$ buckets.\n",
    "* We're interested in $n$, number of planes, so that $2^{n}= 625$. Now, we can calculate $n=\\log_{2}625 = 9.29 \\approx 10$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_PLANES = 10\n",
    "N_UNIVERSES = 25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"3-4\"></a>\n",
    "\n",
    "## 3.4 Getting the hash number for a vector\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"ex-09\"></a>\n",
    "\n",
    "### Implementing hash buckets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "planes_l = [np.random.normal(size=(N_DIMS, N_PLANES))\n",
    "            for _ in range(N_UNIVERSES)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25, 300, 10)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(planes_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hash_value_of_vector(v, planes):\n",
    "    \"\"\"Create a hash for a vector; hash_id says which random hash to use.\n",
    "    Input:\n",
    "        - v:  vector of tweet. It's dimension is (1, N_DIMS)\n",
    "        - planes: matrix of dimension (N_DIMS, N_PLANES) - the set of planes that divide up the region\n",
    "    Output:\n",
    "        - res: a number which is used as a hash for your vector\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    dot_product = np.dot(v,planes)\n",
    "    sign_of_dot_product = np.sign(dot_product)\n",
    "    h = (sign_of_dot_product >= 0)\n",
    "    h = np.squeeze(h)\n",
    "    hash_value = 0\n",
    "    n_planes = planes.shape[1]\n",
    "    for i in range(n_planes):\n",
    "        hash_value += (2**i)*h[i]\n",
    "\n",
    "    hash_value = int(hash_value)\n",
    "\n",
    "    return hash_value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The hash value for this vector, and the set of planes at index 0, is 768\n"
     ]
    }
   ],
   "source": [
    "\n",
    "np.random.seed(0)\n",
    "idx = 0\n",
    "planes = planes_l[idx] \n",
    "vec = np.random.rand(1, 300)\n",
    "print(f\" The hash value for this vector,\",\n",
    "      f\"and the set of planes at index {idx},\",\n",
    "      f\"is {hash_value_of_vector(vec, planes)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 300)\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(vec))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"3-5\"></a>\n",
    "\n",
    "## 3.5 Creating a hash table\n",
    "\n",
    "<a name=\"ex-10\"></a>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_hash_table(vecs, planes):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "        - vecs: list of vectors to be hashed.\n",
    "        - planes: the matrix of planes in a single \"universe\", with shape (embedding dimensions, number of planes).\n",
    "    Output:\n",
    "        - hash_table: dictionary - keys are hashes, values are lists of vectors (hash buckets)\n",
    "        - id_table: dictionary - keys are hashes, values are list of vectors id's\n",
    "                            (it's used to know which tweet corresponds to the hashed vector)\n",
    "    \"\"\"\n",
    "    num_of_planes = planes.shape[1]\n",
    "    num_buckets = 2**num_of_planes\n",
    "    hash_table = {i:[] for i in range(num_buckets)}\n",
    "    id_table = {i:[] for i in range(num_buckets)}\n",
    "    for i, v in enumerate(vecs):\n",
    "        h =  hash_value_of_vector(v, planes)\n",
    "        hash_table[h].append(v)\n",
    "        id_table[h].append(i)\n",
    "\n",
    "    return hash_table, id_table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The hash table at key 0 has 3 document vectors\n",
      "The id table at key 0 has 3\n",
      "The first 5 document indices stored at key 0 of are [3276, 3281, 3282]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "planes = planes_l[0]  \n",
    "vec = np.random.rand(1, 300)\n",
    "tmp_hash_table, tmp_id_table = make_hash_table(document_vecs, planes)\n",
    "\n",
    "print(f\"The hash table at key 0 has {len(tmp_hash_table[0])} document vectors\")\n",
    "print(f\"The id table at key 0 has {len(tmp_id_table[0])}\")\n",
    "print(f\"The first 5 document indices stored at key 0 of are {tmp_id_table[0][0:5]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"3-6\"></a>\n",
    "\n",
    "### 3.6 Creating all hash tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on hash universe #: 0\n",
      "working on hash universe #: 1\n",
      "working on hash universe #: 2\n",
      "working on hash universe #: 3\n",
      "working on hash universe #: 4\n",
      "working on hash universe #: 5\n",
      "working on hash universe #: 6\n",
      "working on hash universe #: 7\n",
      "working on hash universe #: 8\n",
      "working on hash universe #: 9\n",
      "working on hash universe #: 10\n",
      "working on hash universe #: 11\n",
      "working on hash universe #: 12\n",
      "working on hash universe #: 13\n",
      "working on hash universe #: 14\n",
      "working on hash universe #: 15\n",
      "working on hash universe #: 16\n",
      "working on hash universe #: 17\n",
      "working on hash universe #: 18\n",
      "working on hash universe #: 19\n",
      "working on hash universe #: 20\n",
      "working on hash universe #: 21\n",
      "working on hash universe #: 22\n",
      "working on hash universe #: 23\n",
      "working on hash universe #: 24\n"
     ]
    }
   ],
   "source": [
    "# Creating the hashtables\n",
    "hash_tables = []\n",
    "id_tables = []\n",
    "for universe_id in range(N_UNIVERSES):  \n",
    "    print('working on hash universe #:', universe_id)\n",
    "    planes = planes_l[universe_id]\n",
    "    hash_table, id_table = make_hash_table(document_vecs, planes)\n",
    "    hash_tables.append(hash_table)\n",
    "    id_tables.append(id_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approximate K-NN\n",
    "\n",
    "<a name=\"ex-11\"></a>\n",
    "\n",
    "\n",
    "Implement approximate K nearest neighbors using locality sensitive hashing,\n",
    "to search for documents that are similar to a given document "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "def approximate_knn(doc_id, v, planes_l, k=1, num_universes_to_use=N_UNIVERSES):\n",
    "    \"\"\"Search for k-NN using hashes.\"\"\"\n",
    "    assert num_universes_to_use <= N_UNIVERSES\n",
    "    vecs_to_consider_l = list()\n",
    "    ids_to_consider_l = list()\n",
    "    ids_to_consider_set = set()\n",
    "    for universe_id in range(num_universes_to_use):\n",
    "\n",
    "        planes = planes_l[universe_id] \n",
    "        hash_value = hash_value_of_vector(v.reshape((1,len(v))), planes)  \n",
    "        hash_table = make_hash_table(v.reshape((1,len(v))), planes)[0]\n",
    "        document_vectors_l = hash_table[hash_value]\n",
    "        id_table = make_hash_table(v.reshape((1,len(v))), planes)[1]\n",
    "        new_ids_to_consider = id_table[hash_value]\n",
    "        if doc_id in new_ids_to_consider:\n",
    "            new_ids_to_consider.remove(doc_id)\n",
    "            print(f\"removed doc_id {doc_id} of input vector from new_ids_to_search\")\n",
    "\n",
    "        for i, new_id in enumerate(new_ids_to_consider):\n",
    "\n",
    "            if new_id not in ids_to_consider_set:\n",
    "\n",
    "                document_vector_at_i = document_vectors_l[i:]\n",
    "                vecs_to_consider_l.append(document_vector_at_i)\n",
    "\n",
    "                ids_to_consider_l.append(new_id)\n",
    "                ids_to_consider_set.add(new_id)\n",
    "\n",
    "\n",
    "    print(\"Fast considering %d vecs\" % len(vecs_to_consider_l))\n",
    "\n",
    "    vecs_to_consider_arr = np.array(vecs_to_consider_l)\n",
    "    nearest_neighbor_idx_l = nearest_neighbor(v.reshape((1,len(v))), vecs_to_consider_arr, k=k)\n",
    "    nearest_neighbor_ids = [ids_to_consider_l[idx]\n",
    "                            for idx in nearest_neighbor_idx_l]\n",
    "\n",
    "    return nearest_neighbor_ids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_id = 0\n",
    "doc_to_search = all_tweets[doc_id]\n",
    "vec_to_search = document_vecs[doc_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "removed doc_id 0 of input vector from new_ids_to_search\n",
      "removed doc_id 0 of input vector from new_ids_to_search\n",
      "removed doc_id 0 of input vector from new_ids_to_search\n",
      "removed doc_id 0 of input vector from new_ids_to_search\n",
      "removed doc_id 0 of input vector from new_ids_to_search\n",
      "Fast considering 0 vecs\n"
     ]
    }
   ],
   "source": [
    "nearest_neighbor_ids = approximate_knn(\n",
    "    doc_id, vec_to_search, planes_l, k=3, num_universes_to_use=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({0: [],\n",
       "  1: [],\n",
       "  2: [],\n",
       "  3: [],\n",
       "  4: [],\n",
       "  5: [],\n",
       "  6: [],\n",
       "  7: [],\n",
       "  8: [],\n",
       "  9: [],\n",
       "  10: [],\n",
       "  11: [],\n",
       "  12: [],\n",
       "  13: [],\n",
       "  14: [],\n",
       "  15: [],\n",
       "  16: [],\n",
       "  17: [],\n",
       "  18: [],\n",
       "  19: [],\n",
       "  20: [],\n",
       "  21: [],\n",
       "  22: [],\n",
       "  23: [],\n",
       "  24: [],\n",
       "  25: [],\n",
       "  26: [],\n",
       "  27: [],\n",
       "  28: [],\n",
       "  29: [],\n",
       "  30: [],\n",
       "  31: [],\n",
       "  32: [],\n",
       "  33: [],\n",
       "  34: [],\n",
       "  35: [],\n",
       "  36: [],\n",
       "  37: [],\n",
       "  38: [],\n",
       "  39: [],\n",
       "  40: [],\n",
       "  41: [],\n",
       "  42: [],\n",
       "  43: [],\n",
       "  44: [],\n",
       "  45: [],\n",
       "  46: [],\n",
       "  47: [],\n",
       "  48: [],\n",
       "  49: [],\n",
       "  50: [],\n",
       "  51: [],\n",
       "  52: [],\n",
       "  53: [],\n",
       "  54: [],\n",
       "  55: [],\n",
       "  56: [],\n",
       "  57: [],\n",
       "  58: [],\n",
       "  59: [],\n",
       "  60: [],\n",
       "  61: [],\n",
       "  62: [],\n",
       "  63: [],\n",
       "  64: [],\n",
       "  65: [],\n",
       "  66: [],\n",
       "  67: [],\n",
       "  68: [],\n",
       "  69: [],\n",
       "  70: [],\n",
       "  71: [],\n",
       "  72: [],\n",
       "  73: [],\n",
       "  74: [],\n",
       "  75: [],\n",
       "  76: [],\n",
       "  77: [],\n",
       "  78: [],\n",
       "  79: [],\n",
       "  80: [],\n",
       "  81: [],\n",
       "  82: [],\n",
       "  83: [],\n",
       "  84: [],\n",
       "  85: [],\n",
       "  86: [],\n",
       "  87: [],\n",
       "  88: [],\n",
       "  89: [],\n",
       "  90: [],\n",
       "  91: [],\n",
       "  92: [],\n",
       "  93: [],\n",
       "  94: [],\n",
       "  95: [],\n",
       "  96: [],\n",
       "  97: [],\n",
       "  98: [],\n",
       "  99: [],\n",
       "  100: [],\n",
       "  101: [],\n",
       "  102: [],\n",
       "  103: [],\n",
       "  104: [],\n",
       "  105: [],\n",
       "  106: [],\n",
       "  107: [],\n",
       "  108: [],\n",
       "  109: [],\n",
       "  110: [],\n",
       "  111: [],\n",
       "  112: [],\n",
       "  113: [],\n",
       "  114: [],\n",
       "  115: [],\n",
       "  116: [],\n",
       "  117: [],\n",
       "  118: [],\n",
       "  119: [],\n",
       "  120: [],\n",
       "  121: [],\n",
       "  122: [],\n",
       "  123: [],\n",
       "  124: [],\n",
       "  125: [],\n",
       "  126: [],\n",
       "  127: [],\n",
       "  128: [],\n",
       "  129: [],\n",
       "  130: [],\n",
       "  131: [],\n",
       "  132: [],\n",
       "  133: [],\n",
       "  134: [],\n",
       "  135: [],\n",
       "  136: [],\n",
       "  137: [],\n",
       "  138: [],\n",
       "  139: [],\n",
       "  140: [],\n",
       "  141: [],\n",
       "  142: [],\n",
       "  143: [],\n",
       "  144: [],\n",
       "  145: [],\n",
       "  146: [],\n",
       "  147: [],\n",
       "  148: [],\n",
       "  149: [],\n",
       "  150: [],\n",
       "  151: [],\n",
       "  152: [],\n",
       "  153: [],\n",
       "  154: [],\n",
       "  155: [],\n",
       "  156: [],\n",
       "  157: [],\n",
       "  158: [],\n",
       "  159: [],\n",
       "  160: [],\n",
       "  161: [],\n",
       "  162: [],\n",
       "  163: [],\n",
       "  164: [],\n",
       "  165: [],\n",
       "  166: [],\n",
       "  167: [],\n",
       "  168: [],\n",
       "  169: [],\n",
       "  170: [],\n",
       "  171: [],\n",
       "  172: [],\n",
       "  173: [],\n",
       "  174: [],\n",
       "  175: [],\n",
       "  176: [],\n",
       "  177: [],\n",
       "  178: [],\n",
       "  179: [],\n",
       "  180: [],\n",
       "  181: [],\n",
       "  182: [],\n",
       "  183: [],\n",
       "  184: [],\n",
       "  185: [],\n",
       "  186: [],\n",
       "  187: [],\n",
       "  188: [],\n",
       "  189: [],\n",
       "  190: [],\n",
       "  191: [],\n",
       "  192: [],\n",
       "  193: [],\n",
       "  194: [],\n",
       "  195: [],\n",
       "  196: [],\n",
       "  197: [],\n",
       "  198: [],\n",
       "  199: [],\n",
       "  200: [],\n",
       "  201: [],\n",
       "  202: [],\n",
       "  203: [],\n",
       "  204: [],\n",
       "  205: [],\n",
       "  206: [],\n",
       "  207: [],\n",
       "  208: [],\n",
       "  209: [],\n",
       "  210: [],\n",
       "  211: [],\n",
       "  212: [],\n",
       "  213: [],\n",
       "  214: [],\n",
       "  215: [],\n",
       "  216: [],\n",
       "  217: [],\n",
       "  218: [],\n",
       "  219: [],\n",
       "  220: [],\n",
       "  221: [],\n",
       "  222: [],\n",
       "  223: [],\n",
       "  224: [array([ 4.82177734e-02, -1.90429688e-02,  1.58203125e-01, -1.88476562e-01,\n",
       "          -1.13525391e-01, -1.64062500e-01, -1.55029297e-01, -6.39648438e-01,\n",
       "           5.20019531e-01,  4.88281250e-02,  3.13415527e-01, -4.41894531e-02,\n",
       "           2.24151611e-01, -2.44140625e-03, -1.53137207e-01,  2.27539062e-01,\n",
       "           4.15649414e-02, -2.52273560e-01, -5.08300781e-01,  3.85742188e-02,\n",
       "           1.88598633e-01,  3.41796875e-01, -6.57226562e-01, -1.98303223e-01,\n",
       "          -1.52343750e-01, -2.04101562e-01, -4.39453125e-02,  2.14843750e-01,\n",
       "          -6.95800781e-02,  3.18298340e-02,  1.23291016e-01,  1.03759766e-02,\n",
       "           2.77099609e-01,  8.15429688e-02,  3.12255859e-01, -1.25976562e-01,\n",
       "          -1.20361328e-01,  1.80664062e-02, -4.78515625e-01,  1.52709961e-01,\n",
       "           1.12792969e-01, -5.85853577e-01,  3.35693359e-02,  1.97753906e-02,\n",
       "          -3.06640625e-01,  4.82940674e-02, -2.44140625e-04, -1.87988281e-01,\n",
       "           2.60742188e-01,  1.31225586e-01, -7.08007812e-02, -9.04541016e-02,\n",
       "           5.14221191e-03, -1.95007324e-02, -1.68212891e-01, -2.22930908e-02,\n",
       "          -1.44042969e-02, -1.36230469e-01,  3.90625000e-01, -2.52441406e-01,\n",
       "          -1.84051514e-01,  4.54101562e-01, -3.26660156e-01,  5.00488281e-02,\n",
       "          -4.22973633e-02,  2.34130859e-01,  1.15539551e-01,  1.80236816e-01,\n",
       "           3.32031250e-01,  4.17480469e-01,  3.89099121e-02, -3.64257812e-01,\n",
       "           1.72119141e-01,  2.31933594e-01, -3.14453125e-01, -9.74121094e-02,\n",
       "          -1.14013672e-01,  2.25097656e-01,  4.24560547e-01, -2.24365234e-01,\n",
       "           2.97119141e-01, -4.72167969e-01,  1.46972656e-01,  3.17504883e-01,\n",
       "           1.37695312e-01, -3.52539062e-01, -5.01953125e-01, -5.01220703e-01,\n",
       "           2.77099609e-02,  2.05566406e-01,  4.19433594e-01,  1.83837891e-01,\n",
       "          -2.86468506e-01, -1.93847656e-01, -3.10241699e-01, -1.85546875e-01,\n",
       "           3.78417969e-02,  2.77343750e-01, -2.39624023e-01, -2.09228516e-01,\n",
       "           1.49414062e-01,  4.02832031e-02, -1.76391602e-01, -3.36914062e-02,\n",
       "          -4.78515625e-01, -2.31445312e-01, -2.46490479e-01, -3.51562500e-02,\n",
       "          -1.24969482e-01, -3.24157715e-01,  1.10107422e-01, -5.46875000e-02,\n",
       "           2.64892578e-01,  1.47705078e-01, -1.11389160e-02,  1.46484375e-03,\n",
       "           3.37646484e-01,  1.80786133e-01,  4.23339844e-01, -2.47070312e-01,\n",
       "          -2.88726807e-01, -4.96582031e-01, -1.92016602e-01, -3.32031250e-02,\n",
       "          -4.39453125e-02, -2.31445312e-01,  1.24511719e-01, -3.50097656e-01,\n",
       "           2.13317871e-01,  3.02734375e-01, -1.40380859e-01, -3.11645508e-01,\n",
       "           1.26647949e-01, -1.66381836e-01, -1.71875000e-01, -3.39111328e-01,\n",
       "           7.05566406e-02,  6.28662109e-03,  3.41796875e-02,  1.22070312e-01,\n",
       "           1.26464844e-01, -3.48144531e-01,  7.47070312e-02, -3.09082031e-01,\n",
       "           7.39746094e-02,  2.96875000e-01, -5.20935059e-02, -3.30078125e-01,\n",
       "           5.94482422e-02, -5.22460938e-02, -5.00488281e-02,  4.25781250e-01,\n",
       "          -1.22314453e-01,  1.20361328e-01,  4.95117188e-01, -3.19580078e-01,\n",
       "          -2.43240356e-01, -3.38623047e-01, -2.68554688e-03, -6.39648438e-02,\n",
       "          -9.44824219e-02, -1.57714844e-01,  2.51953125e-01,  1.72851562e-01,\n",
       "          -3.44238281e-02, -2.51953125e-01,  2.47009277e-01, -3.03833008e-01,\n",
       "           1.75781250e-01,  1.02050781e-01,  1.43066406e-01,  2.34375000e-02,\n",
       "          -6.68945312e-02, -4.54040527e-01,  6.76269531e-02, -4.64477539e-01,\n",
       "          -1.33361816e-02, -1.29516602e-01, -3.02734375e-02, -2.68859863e-02,\n",
       "          -2.71484375e-01, -1.59423828e-01,  2.89916992e-01,  1.28906250e-01,\n",
       "           1.07299805e-01,  2.63916016e-01,  2.63183594e-01,  4.29687500e-02,\n",
       "           2.59277344e-01, -2.29492188e-01,  4.27246094e-01, -1.00463867e-01,\n",
       "          -8.66699219e-02,  1.13281250e-01, -4.57031250e-01,  2.53906250e-02,\n",
       "           7.32421875e-02,  8.97827148e-02, -1.39648438e-01, -4.44335938e-01,\n",
       "           8.76464844e-02,  4.94873047e-01,  1.50466919e-01, -4.90722656e-02,\n",
       "          -2.46093750e-01, -1.69677734e-01, -6.83593750e-03, -4.39453125e-03,\n",
       "           4.98046875e-02, -3.01269531e-01,  3.03222656e-01, -2.39990234e-01,\n",
       "          -1.39831543e-01,  9.79003906e-02, -2.77343750e-01,  1.77368164e-01,\n",
       "          -3.63769531e-02, -2.50488281e-01, -6.56738281e-02,  2.19726562e-01,\n",
       "           1.66992188e-01,  3.17382812e-03,  1.40502930e-01,  2.63671875e-01,\n",
       "          -1.24511719e-02, -4.21875000e-01,  3.17810059e-01, -7.10449219e-02,\n",
       "           4.29687500e-02,  7.42187500e-02, -3.52386475e-01, -4.26757812e-01,\n",
       "          -1.07055664e-01,  1.52709961e-01, -2.48779297e-01,  5.18035889e-02,\n",
       "           1.91467285e-01, -1.86035156e-01, -1.55914307e-01, -3.03649902e-01,\n",
       "           2.25097656e-01, -5.10253906e-02, -1.33789062e-01, -4.29199219e-01,\n",
       "          -4.48608398e-02,  1.20605469e-01,  1.32446289e-01, -1.32812500e-01,\n",
       "           2.06298828e-02,  1.95312500e-02, -2.22290039e-01,  2.86010742e-01,\n",
       "          -7.20825195e-02, -1.14929199e-01,  5.17578125e-02,  5.48828125e-01,\n",
       "           6.68945312e-02,  2.54394531e-01, -1.33056641e-02,  1.44042969e-02,\n",
       "           3.12500000e-01,  8.41522217e-02,  1.42089844e-01, -1.26953125e-01,\n",
       "           4.07714844e-01,  2.34863281e-01, -8.83789062e-02,  6.58569336e-01,\n",
       "          -2.52929688e-01,  9.17968750e-02,  5.20629883e-02,  4.18945312e-01,\n",
       "           3.29589844e-02,  9.03320312e-02, -2.73864746e-01, -3.07128906e-01,\n",
       "          -3.02215576e-01, -7.07031250e-01, -2.23022461e-01,  1.54785156e-01,\n",
       "           1.28173828e-01,  1.89697266e-01, -3.70361328e-01,  6.91406250e-01,\n",
       "           2.53051758e-01, -1.38427734e-01, -5.78125000e-01,  1.78222656e-01,\n",
       "           5.01953125e-01, -1.51367188e-02,  2.57656097e-01, -2.04101562e-01,\n",
       "          -3.75244141e-01, -1.70043945e-01, -2.65136719e-01, -2.87597656e-01,\n",
       "          -2.08251953e-01,  2.73437500e-01,  3.00170898e-01, -8.97827148e-02])],\n",
       "  225: [],\n",
       "  226: [],\n",
       "  227: [],\n",
       "  228: [],\n",
       "  229: [],\n",
       "  230: [],\n",
       "  231: [],\n",
       "  232: [],\n",
       "  233: [],\n",
       "  234: [],\n",
       "  235: [],\n",
       "  236: [],\n",
       "  237: [],\n",
       "  238: [],\n",
       "  239: [],\n",
       "  240: [],\n",
       "  241: [],\n",
       "  242: [],\n",
       "  243: [],\n",
       "  244: [],\n",
       "  245: [],\n",
       "  246: [],\n",
       "  247: [],\n",
       "  248: [],\n",
       "  249: [],\n",
       "  250: [],\n",
       "  251: [],\n",
       "  252: [],\n",
       "  253: [],\n",
       "  254: [],\n",
       "  255: [],\n",
       "  256: [],\n",
       "  257: [],\n",
       "  258: [],\n",
       "  259: [],\n",
       "  260: [],\n",
       "  261: [],\n",
       "  262: [],\n",
       "  263: [],\n",
       "  264: [],\n",
       "  265: [],\n",
       "  266: [],\n",
       "  267: [],\n",
       "  268: [],\n",
       "  269: [],\n",
       "  270: [],\n",
       "  271: [],\n",
       "  272: [],\n",
       "  273: [],\n",
       "  274: [],\n",
       "  275: [],\n",
       "  276: [],\n",
       "  277: [],\n",
       "  278: [],\n",
       "  279: [],\n",
       "  280: [],\n",
       "  281: [],\n",
       "  282: [],\n",
       "  283: [],\n",
       "  284: [],\n",
       "  285: [],\n",
       "  286: [],\n",
       "  287: [],\n",
       "  288: [],\n",
       "  289: [],\n",
       "  290: [],\n",
       "  291: [],\n",
       "  292: [],\n",
       "  293: [],\n",
       "  294: [],\n",
       "  295: [],\n",
       "  296: [],\n",
       "  297: [],\n",
       "  298: [],\n",
       "  299: [],\n",
       "  300: [],\n",
       "  301: [],\n",
       "  302: [],\n",
       "  303: [],\n",
       "  304: [],\n",
       "  305: [],\n",
       "  306: [],\n",
       "  307: [],\n",
       "  308: [],\n",
       "  309: [],\n",
       "  310: [],\n",
       "  311: [],\n",
       "  312: [],\n",
       "  313: [],\n",
       "  314: [],\n",
       "  315: [],\n",
       "  316: [],\n",
       "  317: [],\n",
       "  318: [],\n",
       "  319: [],\n",
       "  320: [],\n",
       "  321: [],\n",
       "  322: [],\n",
       "  323: [],\n",
       "  324: [],\n",
       "  325: [],\n",
       "  326: [],\n",
       "  327: [],\n",
       "  328: [],\n",
       "  329: [],\n",
       "  330: [],\n",
       "  331: [],\n",
       "  332: [],\n",
       "  333: [],\n",
       "  334: [],\n",
       "  335: [],\n",
       "  336: [],\n",
       "  337: [],\n",
       "  338: [],\n",
       "  339: [],\n",
       "  340: [],\n",
       "  341: [],\n",
       "  342: [],\n",
       "  343: [],\n",
       "  344: [],\n",
       "  345: [],\n",
       "  346: [],\n",
       "  347: [],\n",
       "  348: [],\n",
       "  349: [],\n",
       "  350: [],\n",
       "  351: [],\n",
       "  352: [],\n",
       "  353: [],\n",
       "  354: [],\n",
       "  355: [],\n",
       "  356: [],\n",
       "  357: [],\n",
       "  358: [],\n",
       "  359: [],\n",
       "  360: [],\n",
       "  361: [],\n",
       "  362: [],\n",
       "  363: [],\n",
       "  364: [],\n",
       "  365: [],\n",
       "  366: [],\n",
       "  367: [],\n",
       "  368: [],\n",
       "  369: [],\n",
       "  370: [],\n",
       "  371: [],\n",
       "  372: [],\n",
       "  373: [],\n",
       "  374: [],\n",
       "  375: [],\n",
       "  376: [],\n",
       "  377: [],\n",
       "  378: [],\n",
       "  379: [],\n",
       "  380: [],\n",
       "  381: [],\n",
       "  382: [],\n",
       "  383: [],\n",
       "  384: [],\n",
       "  385: [],\n",
       "  386: [],\n",
       "  387: [],\n",
       "  388: [],\n",
       "  389: [],\n",
       "  390: [],\n",
       "  391: [],\n",
       "  392: [],\n",
       "  393: [],\n",
       "  394: [],\n",
       "  395: [],\n",
       "  396: [],\n",
       "  397: [],\n",
       "  398: [],\n",
       "  399: [],\n",
       "  400: [],\n",
       "  401: [],\n",
       "  402: [],\n",
       "  403: [],\n",
       "  404: [],\n",
       "  405: [],\n",
       "  406: [],\n",
       "  407: [],\n",
       "  408: [],\n",
       "  409: [],\n",
       "  410: [],\n",
       "  411: [],\n",
       "  412: [],\n",
       "  413: [],\n",
       "  414: [],\n",
       "  415: [],\n",
       "  416: [],\n",
       "  417: [],\n",
       "  418: [],\n",
       "  419: [],\n",
       "  420: [],\n",
       "  421: [],\n",
       "  422: [],\n",
       "  423: [],\n",
       "  424: [],\n",
       "  425: [],\n",
       "  426: [],\n",
       "  427: [],\n",
       "  428: [],\n",
       "  429: [],\n",
       "  430: [],\n",
       "  431: [],\n",
       "  432: [],\n",
       "  433: [],\n",
       "  434: [],\n",
       "  435: [],\n",
       "  436: [],\n",
       "  437: [],\n",
       "  438: [],\n",
       "  439: [],\n",
       "  440: [],\n",
       "  441: [],\n",
       "  442: [],\n",
       "  443: [],\n",
       "  444: [],\n",
       "  445: [],\n",
       "  446: [],\n",
       "  447: [],\n",
       "  448: [],\n",
       "  449: [],\n",
       "  450: [],\n",
       "  451: [],\n",
       "  452: [],\n",
       "  453: [],\n",
       "  454: [],\n",
       "  455: [],\n",
       "  456: [],\n",
       "  457: [],\n",
       "  458: [],\n",
       "  459: [],\n",
       "  460: [],\n",
       "  461: [],\n",
       "  462: [],\n",
       "  463: [],\n",
       "  464: [],\n",
       "  465: [],\n",
       "  466: [],\n",
       "  467: [],\n",
       "  468: [],\n",
       "  469: [],\n",
       "  470: [],\n",
       "  471: [],\n",
       "  472: [],\n",
       "  473: [],\n",
       "  474: [],\n",
       "  475: [],\n",
       "  476: [],\n",
       "  477: [],\n",
       "  478: [],\n",
       "  479: [],\n",
       "  480: [],\n",
       "  481: [],\n",
       "  482: [],\n",
       "  483: [],\n",
       "  484: [],\n",
       "  485: [],\n",
       "  486: [],\n",
       "  487: [],\n",
       "  488: [],\n",
       "  489: [],\n",
       "  490: [],\n",
       "  491: [],\n",
       "  492: [],\n",
       "  493: [],\n",
       "  494: [],\n",
       "  495: [],\n",
       "  496: [],\n",
       "  497: [],\n",
       "  498: [],\n",
       "  499: [],\n",
       "  500: [],\n",
       "  501: [],\n",
       "  502: [],\n",
       "  503: [],\n",
       "  504: [],\n",
       "  505: [],\n",
       "  506: [],\n",
       "  507: [],\n",
       "  508: [],\n",
       "  509: [],\n",
       "  510: [],\n",
       "  511: [],\n",
       "  512: [],\n",
       "  513: [],\n",
       "  514: [],\n",
       "  515: [],\n",
       "  516: [],\n",
       "  517: [],\n",
       "  518: [],\n",
       "  519: [],\n",
       "  520: [],\n",
       "  521: [],\n",
       "  522: [],\n",
       "  523: [],\n",
       "  524: [],\n",
       "  525: [],\n",
       "  526: [],\n",
       "  527: [],\n",
       "  528: [],\n",
       "  529: [],\n",
       "  530: [],\n",
       "  531: [],\n",
       "  532: [],\n",
       "  533: [],\n",
       "  534: [],\n",
       "  535: [],\n",
       "  536: [],\n",
       "  537: [],\n",
       "  538: [],\n",
       "  539: [],\n",
       "  540: [],\n",
       "  541: [],\n",
       "  542: [],\n",
       "  543: [],\n",
       "  544: [],\n",
       "  545: [],\n",
       "  546: [],\n",
       "  547: [],\n",
       "  548: [],\n",
       "  549: [],\n",
       "  550: [],\n",
       "  551: [],\n",
       "  552: [],\n",
       "  553: [],\n",
       "  554: [],\n",
       "  555: [],\n",
       "  556: [],\n",
       "  557: [],\n",
       "  558: [],\n",
       "  559: [],\n",
       "  560: [],\n",
       "  561: [],\n",
       "  562: [],\n",
       "  563: [],\n",
       "  564: [],\n",
       "  565: [],\n",
       "  566: [],\n",
       "  567: [],\n",
       "  568: [],\n",
       "  569: [],\n",
       "  570: [],\n",
       "  571: [],\n",
       "  572: [],\n",
       "  573: [],\n",
       "  574: [],\n",
       "  575: [],\n",
       "  576: [],\n",
       "  577: [],\n",
       "  578: [],\n",
       "  579: [],\n",
       "  580: [],\n",
       "  581: [],\n",
       "  582: [],\n",
       "  583: [],\n",
       "  584: [],\n",
       "  585: [],\n",
       "  586: [],\n",
       "  587: [],\n",
       "  588: [],\n",
       "  589: [],\n",
       "  590: [],\n",
       "  591: [],\n",
       "  592: [],\n",
       "  593: [],\n",
       "  594: [],\n",
       "  595: [],\n",
       "  596: [],\n",
       "  597: [],\n",
       "  598: [],\n",
       "  599: [],\n",
       "  600: [],\n",
       "  601: [],\n",
       "  602: [],\n",
       "  603: [],\n",
       "  604: [],\n",
       "  605: [],\n",
       "  606: [],\n",
       "  607: [],\n",
       "  608: [],\n",
       "  609: [],\n",
       "  610: [],\n",
       "  611: [],\n",
       "  612: [],\n",
       "  613: [],\n",
       "  614: [],\n",
       "  615: [],\n",
       "  616: [],\n",
       "  617: [],\n",
       "  618: [],\n",
       "  619: [],\n",
       "  620: [],\n",
       "  621: [],\n",
       "  622: [],\n",
       "  623: [],\n",
       "  624: [],\n",
       "  625: [],\n",
       "  626: [],\n",
       "  627: [],\n",
       "  628: [],\n",
       "  629: [],\n",
       "  630: [],\n",
       "  631: [],\n",
       "  632: [],\n",
       "  633: [],\n",
       "  634: [],\n",
       "  635: [],\n",
       "  636: [],\n",
       "  637: [],\n",
       "  638: [],\n",
       "  639: [],\n",
       "  640: [],\n",
       "  641: [],\n",
       "  642: [],\n",
       "  643: [],\n",
       "  644: [],\n",
       "  645: [],\n",
       "  646: [],\n",
       "  647: [],\n",
       "  648: [],\n",
       "  649: [],\n",
       "  650: [],\n",
       "  651: [],\n",
       "  652: [],\n",
       "  653: [],\n",
       "  654: [],\n",
       "  655: [],\n",
       "  656: [],\n",
       "  657: [],\n",
       "  658: [],\n",
       "  659: [],\n",
       "  660: [],\n",
       "  661: [],\n",
       "  662: [],\n",
       "  663: [],\n",
       "  664: [],\n",
       "  665: [],\n",
       "  666: [],\n",
       "  667: [],\n",
       "  668: [],\n",
       "  669: [],\n",
       "  670: [],\n",
       "  671: [],\n",
       "  672: [],\n",
       "  673: [],\n",
       "  674: [],\n",
       "  675: [],\n",
       "  676: [],\n",
       "  677: [],\n",
       "  678: [],\n",
       "  679: [],\n",
       "  680: [],\n",
       "  681: [],\n",
       "  682: [],\n",
       "  683: [],\n",
       "  684: [],\n",
       "  685: [],\n",
       "  686: [],\n",
       "  687: [],\n",
       "  688: [],\n",
       "  689: [],\n",
       "  690: [],\n",
       "  691: [],\n",
       "  692: [],\n",
       "  693: [],\n",
       "  694: [],\n",
       "  695: [],\n",
       "  696: [],\n",
       "  697: [],\n",
       "  698: [],\n",
       "  699: [],\n",
       "  700: [],\n",
       "  701: [],\n",
       "  702: [],\n",
       "  703: [],\n",
       "  704: [],\n",
       "  705: [],\n",
       "  706: [],\n",
       "  707: [],\n",
       "  708: [],\n",
       "  709: [],\n",
       "  710: [],\n",
       "  711: [],\n",
       "  712: [],\n",
       "  713: [],\n",
       "  714: [],\n",
       "  715: [],\n",
       "  716: [],\n",
       "  717: [],\n",
       "  718: [],\n",
       "  719: [],\n",
       "  720: [],\n",
       "  721: [],\n",
       "  722: [],\n",
       "  723: [],\n",
       "  724: [],\n",
       "  725: [],\n",
       "  726: [],\n",
       "  727: [],\n",
       "  728: [],\n",
       "  729: [],\n",
       "  730: [],\n",
       "  731: [],\n",
       "  732: [],\n",
       "  733: [],\n",
       "  734: [],\n",
       "  735: [],\n",
       "  736: [],\n",
       "  737: [],\n",
       "  738: [],\n",
       "  739: [],\n",
       "  740: [],\n",
       "  741: [],\n",
       "  742: [],\n",
       "  743: [],\n",
       "  744: [],\n",
       "  745: [],\n",
       "  746: [],\n",
       "  747: [],\n",
       "  748: [],\n",
       "  749: [],\n",
       "  750: [],\n",
       "  751: [],\n",
       "  752: [],\n",
       "  753: [],\n",
       "  754: [],\n",
       "  755: [],\n",
       "  756: [],\n",
       "  757: [],\n",
       "  758: [],\n",
       "  759: [],\n",
       "  760: [],\n",
       "  761: [],\n",
       "  762: [],\n",
       "  763: [],\n",
       "  764: [],\n",
       "  765: [],\n",
       "  766: [],\n",
       "  767: [],\n",
       "  768: [],\n",
       "  769: [],\n",
       "  770: [],\n",
       "  771: [],\n",
       "  772: [],\n",
       "  773: [],\n",
       "  774: [],\n",
       "  775: [],\n",
       "  776: [],\n",
       "  777: [],\n",
       "  778: [],\n",
       "  779: [],\n",
       "  780: [],\n",
       "  781: [],\n",
       "  782: [],\n",
       "  783: [],\n",
       "  784: [],\n",
       "  785: [],\n",
       "  786: [],\n",
       "  787: [],\n",
       "  788: [],\n",
       "  789: [],\n",
       "  790: [],\n",
       "  791: [],\n",
       "  792: [],\n",
       "  793: [],\n",
       "  794: [],\n",
       "  795: [],\n",
       "  796: [],\n",
       "  797: [],\n",
       "  798: [],\n",
       "  799: [],\n",
       "  800: [],\n",
       "  801: [],\n",
       "  802: [],\n",
       "  803: [],\n",
       "  804: [],\n",
       "  805: [],\n",
       "  806: [],\n",
       "  807: [],\n",
       "  808: [],\n",
       "  809: [],\n",
       "  810: [],\n",
       "  811: [],\n",
       "  812: [],\n",
       "  813: [],\n",
       "  814: [],\n",
       "  815: [],\n",
       "  816: [],\n",
       "  817: [],\n",
       "  818: [],\n",
       "  819: [],\n",
       "  820: [],\n",
       "  821: [],\n",
       "  822: [],\n",
       "  823: [],\n",
       "  824: [],\n",
       "  825: [],\n",
       "  826: [],\n",
       "  827: [],\n",
       "  828: [],\n",
       "  829: [],\n",
       "  830: [],\n",
       "  831: [],\n",
       "  832: [],\n",
       "  833: [],\n",
       "  834: [],\n",
       "  835: [],\n",
       "  836: [],\n",
       "  837: [],\n",
       "  838: [],\n",
       "  839: [],\n",
       "  840: [],\n",
       "  841: [],\n",
       "  842: [],\n",
       "  843: [],\n",
       "  844: [],\n",
       "  845: [],\n",
       "  846: [],\n",
       "  847: [],\n",
       "  848: [],\n",
       "  849: [],\n",
       "  850: [],\n",
       "  851: [],\n",
       "  852: [],\n",
       "  853: [],\n",
       "  854: [],\n",
       "  855: [],\n",
       "  856: [],\n",
       "  857: [],\n",
       "  858: [],\n",
       "  859: [],\n",
       "  860: [],\n",
       "  861: [],\n",
       "  862: [],\n",
       "  863: [],\n",
       "  864: [],\n",
       "  865: [],\n",
       "  866: [],\n",
       "  867: [],\n",
       "  868: [],\n",
       "  869: [],\n",
       "  870: [],\n",
       "  871: [],\n",
       "  872: [],\n",
       "  873: [],\n",
       "  874: [],\n",
       "  875: [],\n",
       "  876: [],\n",
       "  877: [],\n",
       "  878: [],\n",
       "  879: [],\n",
       "  880: [],\n",
       "  881: [],\n",
       "  882: [],\n",
       "  883: [],\n",
       "  884: [],\n",
       "  885: [],\n",
       "  886: [],\n",
       "  887: [],\n",
       "  888: [],\n",
       "  889: [],\n",
       "  890: [],\n",
       "  891: [],\n",
       "  892: [],\n",
       "  893: [],\n",
       "  894: [],\n",
       "  895: [],\n",
       "  896: [],\n",
       "  897: [],\n",
       "  898: [],\n",
       "  899: [],\n",
       "  900: [],\n",
       "  901: [],\n",
       "  902: [],\n",
       "  903: [],\n",
       "  904: [],\n",
       "  905: [],\n",
       "  906: [],\n",
       "  907: [],\n",
       "  908: [],\n",
       "  909: [],\n",
       "  910: [],\n",
       "  911: [],\n",
       "  912: [],\n",
       "  913: [],\n",
       "  914: [],\n",
       "  915: [],\n",
       "  916: [],\n",
       "  917: [],\n",
       "  918: [],\n",
       "  919: [],\n",
       "  920: [],\n",
       "  921: [],\n",
       "  922: [],\n",
       "  923: [],\n",
       "  924: [],\n",
       "  925: [],\n",
       "  926: [],\n",
       "  927: [],\n",
       "  928: [],\n",
       "  929: [],\n",
       "  930: [],\n",
       "  931: [],\n",
       "  932: [],\n",
       "  933: [],\n",
       "  934: [],\n",
       "  935: [],\n",
       "  936: [],\n",
       "  937: [],\n",
       "  938: [],\n",
       "  939: [],\n",
       "  940: [],\n",
       "  941: [],\n",
       "  942: [],\n",
       "  943: [],\n",
       "  944: [],\n",
       "  945: [],\n",
       "  946: [],\n",
       "  947: [],\n",
       "  948: [],\n",
       "  949: [],\n",
       "  950: [],\n",
       "  951: [],\n",
       "  952: [],\n",
       "  953: [],\n",
       "  954: [],\n",
       "  955: [],\n",
       "  956: [],\n",
       "  957: [],\n",
       "  958: [],\n",
       "  959: [],\n",
       "  960: [],\n",
       "  961: [],\n",
       "  962: [],\n",
       "  963: [],\n",
       "  964: [],\n",
       "  965: [],\n",
       "  966: [],\n",
       "  967: [],\n",
       "  968: [],\n",
       "  969: [],\n",
       "  970: [],\n",
       "  971: [],\n",
       "  972: [],\n",
       "  973: [],\n",
       "  974: [],\n",
       "  975: [],\n",
       "  976: [],\n",
       "  977: [],\n",
       "  978: [],\n",
       "  979: [],\n",
       "  980: [],\n",
       "  981: [],\n",
       "  982: [],\n",
       "  983: [],\n",
       "  984: [],\n",
       "  985: [],\n",
       "  986: [],\n",
       "  987: [],\n",
       "  988: [],\n",
       "  989: [],\n",
       "  990: [],\n",
       "  991: [],\n",
       "  992: [],\n",
       "  993: [],\n",
       "  994: [],\n",
       "  995: [],\n",
       "  996: [],\n",
       "  997: [],\n",
       "  998: [],\n",
       "  999: [],\n",
       "  ...},\n",
       " {0: [],\n",
       "  1: [],\n",
       "  2: [],\n",
       "  3: [],\n",
       "  4: [],\n",
       "  5: [],\n",
       "  6: [],\n",
       "  7: [],\n",
       "  8: [],\n",
       "  9: [],\n",
       "  10: [],\n",
       "  11: [],\n",
       "  12: [],\n",
       "  13: [],\n",
       "  14: [],\n",
       "  15: [],\n",
       "  16: [],\n",
       "  17: [],\n",
       "  18: [],\n",
       "  19: [],\n",
       "  20: [],\n",
       "  21: [],\n",
       "  22: [],\n",
       "  23: [],\n",
       "  24: [],\n",
       "  25: [],\n",
       "  26: [],\n",
       "  27: [],\n",
       "  28: [],\n",
       "  29: [],\n",
       "  30: [],\n",
       "  31: [],\n",
       "  32: [],\n",
       "  33: [],\n",
       "  34: [],\n",
       "  35: [],\n",
       "  36: [],\n",
       "  37: [],\n",
       "  38: [],\n",
       "  39: [],\n",
       "  40: [],\n",
       "  41: [],\n",
       "  42: [],\n",
       "  43: [],\n",
       "  44: [],\n",
       "  45: [],\n",
       "  46: [],\n",
       "  47: [],\n",
       "  48: [],\n",
       "  49: [],\n",
       "  50: [],\n",
       "  51: [],\n",
       "  52: [],\n",
       "  53: [],\n",
       "  54: [],\n",
       "  55: [],\n",
       "  56: [],\n",
       "  57: [],\n",
       "  58: [],\n",
       "  59: [],\n",
       "  60: [],\n",
       "  61: [],\n",
       "  62: [],\n",
       "  63: [],\n",
       "  64: [],\n",
       "  65: [],\n",
       "  66: [],\n",
       "  67: [],\n",
       "  68: [],\n",
       "  69: [],\n",
       "  70: [],\n",
       "  71: [],\n",
       "  72: [],\n",
       "  73: [],\n",
       "  74: [],\n",
       "  75: [],\n",
       "  76: [],\n",
       "  77: [],\n",
       "  78: [],\n",
       "  79: [],\n",
       "  80: [],\n",
       "  81: [],\n",
       "  82: [],\n",
       "  83: [],\n",
       "  84: [],\n",
       "  85: [],\n",
       "  86: [],\n",
       "  87: [],\n",
       "  88: [],\n",
       "  89: [],\n",
       "  90: [],\n",
       "  91: [],\n",
       "  92: [],\n",
       "  93: [],\n",
       "  94: [],\n",
       "  95: [],\n",
       "  96: [],\n",
       "  97: [],\n",
       "  98: [],\n",
       "  99: [],\n",
       "  100: [],\n",
       "  101: [],\n",
       "  102: [],\n",
       "  103: [],\n",
       "  104: [],\n",
       "  105: [],\n",
       "  106: [],\n",
       "  107: [],\n",
       "  108: [],\n",
       "  109: [],\n",
       "  110: [],\n",
       "  111: [],\n",
       "  112: [],\n",
       "  113: [],\n",
       "  114: [],\n",
       "  115: [],\n",
       "  116: [],\n",
       "  117: [],\n",
       "  118: [],\n",
       "  119: [],\n",
       "  120: [],\n",
       "  121: [],\n",
       "  122: [],\n",
       "  123: [],\n",
       "  124: [],\n",
       "  125: [],\n",
       "  126: [],\n",
       "  127: [],\n",
       "  128: [],\n",
       "  129: [],\n",
       "  130: [],\n",
       "  131: [],\n",
       "  132: [],\n",
       "  133: [],\n",
       "  134: [],\n",
       "  135: [],\n",
       "  136: [],\n",
       "  137: [],\n",
       "  138: [],\n",
       "  139: [],\n",
       "  140: [],\n",
       "  141: [],\n",
       "  142: [],\n",
       "  143: [],\n",
       "  144: [],\n",
       "  145: [],\n",
       "  146: [],\n",
       "  147: [],\n",
       "  148: [],\n",
       "  149: [],\n",
       "  150: [],\n",
       "  151: [],\n",
       "  152: [],\n",
       "  153: [],\n",
       "  154: [],\n",
       "  155: [],\n",
       "  156: [],\n",
       "  157: [],\n",
       "  158: [],\n",
       "  159: [],\n",
       "  160: [],\n",
       "  161: [],\n",
       "  162: [],\n",
       "  163: [],\n",
       "  164: [],\n",
       "  165: [],\n",
       "  166: [],\n",
       "  167: [],\n",
       "  168: [],\n",
       "  169: [],\n",
       "  170: [],\n",
       "  171: [],\n",
       "  172: [],\n",
       "  173: [],\n",
       "  174: [],\n",
       "  175: [],\n",
       "  176: [],\n",
       "  177: [],\n",
       "  178: [],\n",
       "  179: [],\n",
       "  180: [],\n",
       "  181: [],\n",
       "  182: [],\n",
       "  183: [],\n",
       "  184: [],\n",
       "  185: [],\n",
       "  186: [],\n",
       "  187: [],\n",
       "  188: [],\n",
       "  189: [],\n",
       "  190: [],\n",
       "  191: [],\n",
       "  192: [],\n",
       "  193: [],\n",
       "  194: [],\n",
       "  195: [],\n",
       "  196: [],\n",
       "  197: [],\n",
       "  198: [],\n",
       "  199: [],\n",
       "  200: [],\n",
       "  201: [],\n",
       "  202: [],\n",
       "  203: [],\n",
       "  204: [],\n",
       "  205: [],\n",
       "  206: [],\n",
       "  207: [],\n",
       "  208: [],\n",
       "  209: [],\n",
       "  210: [],\n",
       "  211: [],\n",
       "  212: [],\n",
       "  213: [],\n",
       "  214: [],\n",
       "  215: [],\n",
       "  216: [],\n",
       "  217: [],\n",
       "  218: [],\n",
       "  219: [],\n",
       "  220: [],\n",
       "  221: [],\n",
       "  222: [],\n",
       "  223: [],\n",
       "  224: [0],\n",
       "  225: [],\n",
       "  226: [],\n",
       "  227: [],\n",
       "  228: [],\n",
       "  229: [],\n",
       "  230: [],\n",
       "  231: [],\n",
       "  232: [],\n",
       "  233: [],\n",
       "  234: [],\n",
       "  235: [],\n",
       "  236: [],\n",
       "  237: [],\n",
       "  238: [],\n",
       "  239: [],\n",
       "  240: [],\n",
       "  241: [],\n",
       "  242: [],\n",
       "  243: [],\n",
       "  244: [],\n",
       "  245: [],\n",
       "  246: [],\n",
       "  247: [],\n",
       "  248: [],\n",
       "  249: [],\n",
       "  250: [],\n",
       "  251: [],\n",
       "  252: [],\n",
       "  253: [],\n",
       "  254: [],\n",
       "  255: [],\n",
       "  256: [],\n",
       "  257: [],\n",
       "  258: [],\n",
       "  259: [],\n",
       "  260: [],\n",
       "  261: [],\n",
       "  262: [],\n",
       "  263: [],\n",
       "  264: [],\n",
       "  265: [],\n",
       "  266: [],\n",
       "  267: [],\n",
       "  268: [],\n",
       "  269: [],\n",
       "  270: [],\n",
       "  271: [],\n",
       "  272: [],\n",
       "  273: [],\n",
       "  274: [],\n",
       "  275: [],\n",
       "  276: [],\n",
       "  277: [],\n",
       "  278: [],\n",
       "  279: [],\n",
       "  280: [],\n",
       "  281: [],\n",
       "  282: [],\n",
       "  283: [],\n",
       "  284: [],\n",
       "  285: [],\n",
       "  286: [],\n",
       "  287: [],\n",
       "  288: [],\n",
       "  289: [],\n",
       "  290: [],\n",
       "  291: [],\n",
       "  292: [],\n",
       "  293: [],\n",
       "  294: [],\n",
       "  295: [],\n",
       "  296: [],\n",
       "  297: [],\n",
       "  298: [],\n",
       "  299: [],\n",
       "  300: [],\n",
       "  301: [],\n",
       "  302: [],\n",
       "  303: [],\n",
       "  304: [],\n",
       "  305: [],\n",
       "  306: [],\n",
       "  307: [],\n",
       "  308: [],\n",
       "  309: [],\n",
       "  310: [],\n",
       "  311: [],\n",
       "  312: [],\n",
       "  313: [],\n",
       "  314: [],\n",
       "  315: [],\n",
       "  316: [],\n",
       "  317: [],\n",
       "  318: [],\n",
       "  319: [],\n",
       "  320: [],\n",
       "  321: [],\n",
       "  322: [],\n",
       "  323: [],\n",
       "  324: [],\n",
       "  325: [],\n",
       "  326: [],\n",
       "  327: [],\n",
       "  328: [],\n",
       "  329: [],\n",
       "  330: [],\n",
       "  331: [],\n",
       "  332: [],\n",
       "  333: [],\n",
       "  334: [],\n",
       "  335: [],\n",
       "  336: [],\n",
       "  337: [],\n",
       "  338: [],\n",
       "  339: [],\n",
       "  340: [],\n",
       "  341: [],\n",
       "  342: [],\n",
       "  343: [],\n",
       "  344: [],\n",
       "  345: [],\n",
       "  346: [],\n",
       "  347: [],\n",
       "  348: [],\n",
       "  349: [],\n",
       "  350: [],\n",
       "  351: [],\n",
       "  352: [],\n",
       "  353: [],\n",
       "  354: [],\n",
       "  355: [],\n",
       "  356: [],\n",
       "  357: [],\n",
       "  358: [],\n",
       "  359: [],\n",
       "  360: [],\n",
       "  361: [],\n",
       "  362: [],\n",
       "  363: [],\n",
       "  364: [],\n",
       "  365: [],\n",
       "  366: [],\n",
       "  367: [],\n",
       "  368: [],\n",
       "  369: [],\n",
       "  370: [],\n",
       "  371: [],\n",
       "  372: [],\n",
       "  373: [],\n",
       "  374: [],\n",
       "  375: [],\n",
       "  376: [],\n",
       "  377: [],\n",
       "  378: [],\n",
       "  379: [],\n",
       "  380: [],\n",
       "  381: [],\n",
       "  382: [],\n",
       "  383: [],\n",
       "  384: [],\n",
       "  385: [],\n",
       "  386: [],\n",
       "  387: [],\n",
       "  388: [],\n",
       "  389: [],\n",
       "  390: [],\n",
       "  391: [],\n",
       "  392: [],\n",
       "  393: [],\n",
       "  394: [],\n",
       "  395: [],\n",
       "  396: [],\n",
       "  397: [],\n",
       "  398: [],\n",
       "  399: [],\n",
       "  400: [],\n",
       "  401: [],\n",
       "  402: [],\n",
       "  403: [],\n",
       "  404: [],\n",
       "  405: [],\n",
       "  406: [],\n",
       "  407: [],\n",
       "  408: [],\n",
       "  409: [],\n",
       "  410: [],\n",
       "  411: [],\n",
       "  412: [],\n",
       "  413: [],\n",
       "  414: [],\n",
       "  415: [],\n",
       "  416: [],\n",
       "  417: [],\n",
       "  418: [],\n",
       "  419: [],\n",
       "  420: [],\n",
       "  421: [],\n",
       "  422: [],\n",
       "  423: [],\n",
       "  424: [],\n",
       "  425: [],\n",
       "  426: [],\n",
       "  427: [],\n",
       "  428: [],\n",
       "  429: [],\n",
       "  430: [],\n",
       "  431: [],\n",
       "  432: [],\n",
       "  433: [],\n",
       "  434: [],\n",
       "  435: [],\n",
       "  436: [],\n",
       "  437: [],\n",
       "  438: [],\n",
       "  439: [],\n",
       "  440: [],\n",
       "  441: [],\n",
       "  442: [],\n",
       "  443: [],\n",
       "  444: [],\n",
       "  445: [],\n",
       "  446: [],\n",
       "  447: [],\n",
       "  448: [],\n",
       "  449: [],\n",
       "  450: [],\n",
       "  451: [],\n",
       "  452: [],\n",
       "  453: [],\n",
       "  454: [],\n",
       "  455: [],\n",
       "  456: [],\n",
       "  457: [],\n",
       "  458: [],\n",
       "  459: [],\n",
       "  460: [],\n",
       "  461: [],\n",
       "  462: [],\n",
       "  463: [],\n",
       "  464: [],\n",
       "  465: [],\n",
       "  466: [],\n",
       "  467: [],\n",
       "  468: [],\n",
       "  469: [],\n",
       "  470: [],\n",
       "  471: [],\n",
       "  472: [],\n",
       "  473: [],\n",
       "  474: [],\n",
       "  475: [],\n",
       "  476: [],\n",
       "  477: [],\n",
       "  478: [],\n",
       "  479: [],\n",
       "  480: [],\n",
       "  481: [],\n",
       "  482: [],\n",
       "  483: [],\n",
       "  484: [],\n",
       "  485: [],\n",
       "  486: [],\n",
       "  487: [],\n",
       "  488: [],\n",
       "  489: [],\n",
       "  490: [],\n",
       "  491: [],\n",
       "  492: [],\n",
       "  493: [],\n",
       "  494: [],\n",
       "  495: [],\n",
       "  496: [],\n",
       "  497: [],\n",
       "  498: [],\n",
       "  499: [],\n",
       "  500: [],\n",
       "  501: [],\n",
       "  502: [],\n",
       "  503: [],\n",
       "  504: [],\n",
       "  505: [],\n",
       "  506: [],\n",
       "  507: [],\n",
       "  508: [],\n",
       "  509: [],\n",
       "  510: [],\n",
       "  511: [],\n",
       "  512: [],\n",
       "  513: [],\n",
       "  514: [],\n",
       "  515: [],\n",
       "  516: [],\n",
       "  517: [],\n",
       "  518: [],\n",
       "  519: [],\n",
       "  520: [],\n",
       "  521: [],\n",
       "  522: [],\n",
       "  523: [],\n",
       "  524: [],\n",
       "  525: [],\n",
       "  526: [],\n",
       "  527: [],\n",
       "  528: [],\n",
       "  529: [],\n",
       "  530: [],\n",
       "  531: [],\n",
       "  532: [],\n",
       "  533: [],\n",
       "  534: [],\n",
       "  535: [],\n",
       "  536: [],\n",
       "  537: [],\n",
       "  538: [],\n",
       "  539: [],\n",
       "  540: [],\n",
       "  541: [],\n",
       "  542: [],\n",
       "  543: [],\n",
       "  544: [],\n",
       "  545: [],\n",
       "  546: [],\n",
       "  547: [],\n",
       "  548: [],\n",
       "  549: [],\n",
       "  550: [],\n",
       "  551: [],\n",
       "  552: [],\n",
       "  553: [],\n",
       "  554: [],\n",
       "  555: [],\n",
       "  556: [],\n",
       "  557: [],\n",
       "  558: [],\n",
       "  559: [],\n",
       "  560: [],\n",
       "  561: [],\n",
       "  562: [],\n",
       "  563: [],\n",
       "  564: [],\n",
       "  565: [],\n",
       "  566: [],\n",
       "  567: [],\n",
       "  568: [],\n",
       "  569: [],\n",
       "  570: [],\n",
       "  571: [],\n",
       "  572: [],\n",
       "  573: [],\n",
       "  574: [],\n",
       "  575: [],\n",
       "  576: [],\n",
       "  577: [],\n",
       "  578: [],\n",
       "  579: [],\n",
       "  580: [],\n",
       "  581: [],\n",
       "  582: [],\n",
       "  583: [],\n",
       "  584: [],\n",
       "  585: [],\n",
       "  586: [],\n",
       "  587: [],\n",
       "  588: [],\n",
       "  589: [],\n",
       "  590: [],\n",
       "  591: [],\n",
       "  592: [],\n",
       "  593: [],\n",
       "  594: [],\n",
       "  595: [],\n",
       "  596: [],\n",
       "  597: [],\n",
       "  598: [],\n",
       "  599: [],\n",
       "  600: [],\n",
       "  601: [],\n",
       "  602: [],\n",
       "  603: [],\n",
       "  604: [],\n",
       "  605: [],\n",
       "  606: [],\n",
       "  607: [],\n",
       "  608: [],\n",
       "  609: [],\n",
       "  610: [],\n",
       "  611: [],\n",
       "  612: [],\n",
       "  613: [],\n",
       "  614: [],\n",
       "  615: [],\n",
       "  616: [],\n",
       "  617: [],\n",
       "  618: [],\n",
       "  619: [],\n",
       "  620: [],\n",
       "  621: [],\n",
       "  622: [],\n",
       "  623: [],\n",
       "  624: [],\n",
       "  625: [],\n",
       "  626: [],\n",
       "  627: [],\n",
       "  628: [],\n",
       "  629: [],\n",
       "  630: [],\n",
       "  631: [],\n",
       "  632: [],\n",
       "  633: [],\n",
       "  634: [],\n",
       "  635: [],\n",
       "  636: [],\n",
       "  637: [],\n",
       "  638: [],\n",
       "  639: [],\n",
       "  640: [],\n",
       "  641: [],\n",
       "  642: [],\n",
       "  643: [],\n",
       "  644: [],\n",
       "  645: [],\n",
       "  646: [],\n",
       "  647: [],\n",
       "  648: [],\n",
       "  649: [],\n",
       "  650: [],\n",
       "  651: [],\n",
       "  652: [],\n",
       "  653: [],\n",
       "  654: [],\n",
       "  655: [],\n",
       "  656: [],\n",
       "  657: [],\n",
       "  658: [],\n",
       "  659: [],\n",
       "  660: [],\n",
       "  661: [],\n",
       "  662: [],\n",
       "  663: [],\n",
       "  664: [],\n",
       "  665: [],\n",
       "  666: [],\n",
       "  667: [],\n",
       "  668: [],\n",
       "  669: [],\n",
       "  670: [],\n",
       "  671: [],\n",
       "  672: [],\n",
       "  673: [],\n",
       "  674: [],\n",
       "  675: [],\n",
       "  676: [],\n",
       "  677: [],\n",
       "  678: [],\n",
       "  679: [],\n",
       "  680: [],\n",
       "  681: [],\n",
       "  682: [],\n",
       "  683: [],\n",
       "  684: [],\n",
       "  685: [],\n",
       "  686: [],\n",
       "  687: [],\n",
       "  688: [],\n",
       "  689: [],\n",
       "  690: [],\n",
       "  691: [],\n",
       "  692: [],\n",
       "  693: [],\n",
       "  694: [],\n",
       "  695: [],\n",
       "  696: [],\n",
       "  697: [],\n",
       "  698: [],\n",
       "  699: [],\n",
       "  700: [],\n",
       "  701: [],\n",
       "  702: [],\n",
       "  703: [],\n",
       "  704: [],\n",
       "  705: [],\n",
       "  706: [],\n",
       "  707: [],\n",
       "  708: [],\n",
       "  709: [],\n",
       "  710: [],\n",
       "  711: [],\n",
       "  712: [],\n",
       "  713: [],\n",
       "  714: [],\n",
       "  715: [],\n",
       "  716: [],\n",
       "  717: [],\n",
       "  718: [],\n",
       "  719: [],\n",
       "  720: [],\n",
       "  721: [],\n",
       "  722: [],\n",
       "  723: [],\n",
       "  724: [],\n",
       "  725: [],\n",
       "  726: [],\n",
       "  727: [],\n",
       "  728: [],\n",
       "  729: [],\n",
       "  730: [],\n",
       "  731: [],\n",
       "  732: [],\n",
       "  733: [],\n",
       "  734: [],\n",
       "  735: [],\n",
       "  736: [],\n",
       "  737: [],\n",
       "  738: [],\n",
       "  739: [],\n",
       "  740: [],\n",
       "  741: [],\n",
       "  742: [],\n",
       "  743: [],\n",
       "  744: [],\n",
       "  745: [],\n",
       "  746: [],\n",
       "  747: [],\n",
       "  748: [],\n",
       "  749: [],\n",
       "  750: [],\n",
       "  751: [],\n",
       "  752: [],\n",
       "  753: [],\n",
       "  754: [],\n",
       "  755: [],\n",
       "  756: [],\n",
       "  757: [],\n",
       "  758: [],\n",
       "  759: [],\n",
       "  760: [],\n",
       "  761: [],\n",
       "  762: [],\n",
       "  763: [],\n",
       "  764: [],\n",
       "  765: [],\n",
       "  766: [],\n",
       "  767: [],\n",
       "  768: [],\n",
       "  769: [],\n",
       "  770: [],\n",
       "  771: [],\n",
       "  772: [],\n",
       "  773: [],\n",
       "  774: [],\n",
       "  775: [],\n",
       "  776: [],\n",
       "  777: [],\n",
       "  778: [],\n",
       "  779: [],\n",
       "  780: [],\n",
       "  781: [],\n",
       "  782: [],\n",
       "  783: [],\n",
       "  784: [],\n",
       "  785: [],\n",
       "  786: [],\n",
       "  787: [],\n",
       "  788: [],\n",
       "  789: [],\n",
       "  790: [],\n",
       "  791: [],\n",
       "  792: [],\n",
       "  793: [],\n",
       "  794: [],\n",
       "  795: [],\n",
       "  796: [],\n",
       "  797: [],\n",
       "  798: [],\n",
       "  799: [],\n",
       "  800: [],\n",
       "  801: [],\n",
       "  802: [],\n",
       "  803: [],\n",
       "  804: [],\n",
       "  805: [],\n",
       "  806: [],\n",
       "  807: [],\n",
       "  808: [],\n",
       "  809: [],\n",
       "  810: [],\n",
       "  811: [],\n",
       "  812: [],\n",
       "  813: [],\n",
       "  814: [],\n",
       "  815: [],\n",
       "  816: [],\n",
       "  817: [],\n",
       "  818: [],\n",
       "  819: [],\n",
       "  820: [],\n",
       "  821: [],\n",
       "  822: [],\n",
       "  823: [],\n",
       "  824: [],\n",
       "  825: [],\n",
       "  826: [],\n",
       "  827: [],\n",
       "  828: [],\n",
       "  829: [],\n",
       "  830: [],\n",
       "  831: [],\n",
       "  832: [],\n",
       "  833: [],\n",
       "  834: [],\n",
       "  835: [],\n",
       "  836: [],\n",
       "  837: [],\n",
       "  838: [],\n",
       "  839: [],\n",
       "  840: [],\n",
       "  841: [],\n",
       "  842: [],\n",
       "  843: [],\n",
       "  844: [],\n",
       "  845: [],\n",
       "  846: [],\n",
       "  847: [],\n",
       "  848: [],\n",
       "  849: [],\n",
       "  850: [],\n",
       "  851: [],\n",
       "  852: [],\n",
       "  853: [],\n",
       "  854: [],\n",
       "  855: [],\n",
       "  856: [],\n",
       "  857: [],\n",
       "  858: [],\n",
       "  859: [],\n",
       "  860: [],\n",
       "  861: [],\n",
       "  862: [],\n",
       "  863: [],\n",
       "  864: [],\n",
       "  865: [],\n",
       "  866: [],\n",
       "  867: [],\n",
       "  868: [],\n",
       "  869: [],\n",
       "  870: [],\n",
       "  871: [],\n",
       "  872: [],\n",
       "  873: [],\n",
       "  874: [],\n",
       "  875: [],\n",
       "  876: [],\n",
       "  877: [],\n",
       "  878: [],\n",
       "  879: [],\n",
       "  880: [],\n",
       "  881: [],\n",
       "  882: [],\n",
       "  883: [],\n",
       "  884: [],\n",
       "  885: [],\n",
       "  886: [],\n",
       "  887: [],\n",
       "  888: [],\n",
       "  889: [],\n",
       "  890: [],\n",
       "  891: [],\n",
       "  892: [],\n",
       "  893: [],\n",
       "  894: [],\n",
       "  895: [],\n",
       "  896: [],\n",
       "  897: [],\n",
       "  898: [],\n",
       "  899: [],\n",
       "  900: [],\n",
       "  901: [],\n",
       "  902: [],\n",
       "  903: [],\n",
       "  904: [],\n",
       "  905: [],\n",
       "  906: [],\n",
       "  907: [],\n",
       "  908: [],\n",
       "  909: [],\n",
       "  910: [],\n",
       "  911: [],\n",
       "  912: [],\n",
       "  913: [],\n",
       "  914: [],\n",
       "  915: [],\n",
       "  916: [],\n",
       "  917: [],\n",
       "  918: [],\n",
       "  919: [],\n",
       "  920: [],\n",
       "  921: [],\n",
       "  922: [],\n",
       "  923: [],\n",
       "  924: [],\n",
       "  925: [],\n",
       "  926: [],\n",
       "  927: [],\n",
       "  928: [],\n",
       "  929: [],\n",
       "  930: [],\n",
       "  931: [],\n",
       "  932: [],\n",
       "  933: [],\n",
       "  934: [],\n",
       "  935: [],\n",
       "  936: [],\n",
       "  937: [],\n",
       "  938: [],\n",
       "  939: [],\n",
       "  940: [],\n",
       "  941: [],\n",
       "  942: [],\n",
       "  943: [],\n",
       "  944: [],\n",
       "  945: [],\n",
       "  946: [],\n",
       "  947: [],\n",
       "  948: [],\n",
       "  949: [],\n",
       "  950: [],\n",
       "  951: [],\n",
       "  952: [],\n",
       "  953: [],\n",
       "  954: [],\n",
       "  955: [],\n",
       "  956: [],\n",
       "  957: [],\n",
       "  958: [],\n",
       "  959: [],\n",
       "  960: [],\n",
       "  961: [],\n",
       "  962: [],\n",
       "  963: [],\n",
       "  964: [],\n",
       "  965: [],\n",
       "  966: [],\n",
       "  967: [],\n",
       "  968: [],\n",
       "  969: [],\n",
       "  970: [],\n",
       "  971: [],\n",
       "  972: [],\n",
       "  973: [],\n",
       "  974: [],\n",
       "  975: [],\n",
       "  976: [],\n",
       "  977: [],\n",
       "  978: [],\n",
       "  979: [],\n",
       "  980: [],\n",
       "  981: [],\n",
       "  982: [],\n",
       "  983: [],\n",
       "  984: [],\n",
       "  985: [],\n",
       "  986: [],\n",
       "  987: [],\n",
       "  988: [],\n",
       "  989: [],\n",
       "  990: [],\n",
       "  991: [],\n",
       "  992: [],\n",
       "  993: [],\n",
       "  994: [],\n",
       "  995: [],\n",
       "  996: [],\n",
       "  997: [],\n",
       "  998: [],\n",
       "  999: [],\n",
       "  ...})"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "make_hash_table(vec_to_search.reshape((1,len(vec_to_search))), planes_l[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest neighbors for document 0\n",
      "Document contents: #FollowFriday @France_Inte @PKuchly57 @Milipol_Paris for being top engaged members in my community this week :)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Nearest neighbors for document {doc_id}\")\n",
    "print(f\"Document contents: {doc_to_search}\")\n",
    "print(\"\")\n",
    "\n",
    "for neighbor_id in nearest_neighbor_ids:\n",
    "    print(f\"Nearest neighbor at document id {neighbor_id}\")\n",
    "    print(f\"document contents: {all_tweets[neighbor_id]}\")"
   ]
  }
 ],
 "metadata": {
  "coursera": {
   "schema_names": [
    "NLPC1-4"
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
